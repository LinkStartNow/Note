# 基础理论

服务器软件，是一种后台服务应用，用于支持前端应用，其功能有：

- 数据支持
- 数据中转
- 持久化存储

几乎所有的软件都需要服务器支持，无论是网络应用或者是单机应用

## 软件服务器&Web服务器

软件服务器的研发与制作围绕软件功能，不同的软件，主体功能不同，所以服务器实现的侧重也不同，所以软件服务器很难实现共享和共用，软件服务器的开源代码也比较少

而万维网相关的技术栈，标准高度统一，所以开发一个web服务器可以被任何企业或网站使用

市面上占用率最高的几款开源web服务器：

1. Apache
2. Nginx
3. Tomcat

用户自行配置直接使用即可

## 服务器基本职能

1. 网络穿透（数据中转）
2. 高并发（并发连接，并发处理）
3. 较强的吞吐能力（IO）
4. 安全性、可靠性、稳定性
5. 服务器性能指标

## 代理服务器

可以隐藏真实地址，部署负载均衡完成任务分发

可以做安全层，保障服务安全可靠

## 负载均衡

将大量的网络请求，均匀分发到不同的处理机，避免某些处理机高负载，某些负载过低

### 负载均衡策略

1. 轮询分发任务
2. 记录处理机占用情况，按低占用分发
3. 处理量设置，用户请求绑定

## HA高可用

是任务转接方式

可以检测设备异常，如果目标设备异常，则会动态修改目标地址（IP, MAC），重定向目标

## 服务器性能指标

### 每秒钟的响应次数 TPS

### 每秒钟的查询次数 QPS

### 最大并发数量计算

### 每秒响应数量计算

### 吞吐量概念 IO

### 网络IO与CPU的关系

### 压力测试

### 负载测试

# 实践——服务端

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>

#define IP "192.168.19.130"

int server_shutdown;

int main() {
	struct sockaddr_in server_addr, client_addr;
	int server_sock, client_sock;
	char recv_buf[1500];
	char cip[16];
	int rect_len;
	int flag;
	socklen_t addrlen;
	server_shutdown = 1;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}

	// 绑定网络信息
	if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
		perror("bind fail");
		exit(0);
	}

	// 网络连接监听
	listen(server_sock, 128);
	
	while (server_shutdown) {
		// 等待建立连接
		addrlen = sizeof(client_addr);
		if ((client_sock = accept(server_sock, (struct sockaddr*)&client_addr, &addrlen)) > 0) {
			// 客户端连接成功，向客户端反馈欢迎信息
			bzero(recv_buf, sizeof(recv_buf));
			inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
			sprintf(recv_buf, "hi, %s welcome to test server service..\n", cip);
			send(client_sock, recv_buf, strlen(recv_buf), 0);
			printf("server info, client connect success , ip %s, port %d\n", cip, ntohs(client_addr.sin_port));
		}
		else {
			perror("accept fail");
			exit(0);
		}

		// 读取客户端请求
		int recv_len;
		bzero(recv_buf, sizeof(recv_buf));
		while ((recv_len = recv(client_sock, recv_buf, sizeof(recv_buf), 0)) > 0) {
			flag = 0;
			// 处理客户端请求
			while (recv_len > flag) {
				recv_buf[flag] = toupper(recv_buf[flag]);
				++flag;
			}
			// 反馈结果
			send(client_sock, recv_buf, strlen(recv_buf), 0);
			bzero(recv_buf, sizeof(recv_buf));
		// 返回进行下一轮连接等待
		}
	}
	return 0;
}
```

---

# 实践——客户端

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>

#define IP "192.168.19.130"

int main() {
	struct sockaddr_in server_addr;
	int client_sock;
	char recv_buf[1500];
	char cip[16];
	int recv_len;
	socklen_t addrlen;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((client_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}
	
	// 发送第一次连接请求
	if ((connect(client_sock, (struct sockaddr*)&server_addr, sizeof(server_addr))) == -1) {
		perror("connect fail");
		exit(0);
	}
	recv(client_sock, recv_buf, sizeof(recv_buf), 0);
	printf("%s", recv_buf);
	bzero(recv_buf, sizeof(recv_buf));
	while ((fgets(recv_buf, sizeof(recv_buf), stdin)) != NULL) {
		send(client_sock, recv_buf, strlen(recv_buf), 0);
		recv(client_sock, recv_buf, sizeof(recv_buf), 0);
		printf("%s\n", recv_buf);
		bzero(recv_buf, sizeof(recv_buf));
	}
	close(client_sock);
	return 0;
}
```

> 最终实现的功能是，客户端连接上服务端，然后给服务端发信息，服务端将信息中的小写转成大写发回来
>
> 当然也可以不用客户端，直接调用命令也可以连接服务端测试功能：
>
> ```bash
> nc 192.168.19.130 8080
> ```
>
> 其中192.168.19.130是服务端的IP，8080是对应的端口

---

# 实践——单进程服务端，连接多客户端

我们可以通过设置socket和recv的非阻塞来实现该功能

## 连接非阻塞

我们需要使用`fcntl`函数，取出该socket的属性标志，再经过按位异或修改后重新写会，即可实现修改socket的非阻塞，连接也就非阻塞了

```c
// 设置serversock非阻塞
int eflag;
fcntl(server_sock, F_GETFL, &eflag);
eflag |= O_NONBLOCK;
fcntl(server_sock, F_SETFL, eflag);
```

## 接收信息非阻塞

只用修改接收函数的最后一个参数即可

```c
recv(sock_list[i], recv_buf, sizeof(recv_buf), MSG_DONTWAIT)
```

## 完整版

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>
#include <fcntl.h>
#include <errno.h>

#define IP "192.168.19.130"

int server_shutdown;

int sock_list[1024];

int main() {
	struct sockaddr_in server_addr, client_addr;
	int server_sock, client_sock;
	char recv_buf[1500];
	char cip[16];
	int rect_len;
	int flag;
	socklen_t addrlen;
	server_shutdown = 1;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}

	// 绑定网络信息
	if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
		perror("bind fail");
		exit(0);
	}

	// 设置serversock非阻塞
	int eflag;
	fcntl(server_sock, F_GETFL, &eflag);
	eflag |= O_NONBLOCK;
	fcntl(server_sock, F_SETFL, eflag);

	// 网络连接监听
	listen(server_sock, 128);
	
	while (server_shutdown) {
	// 等待建立连接
	addrlen = sizeof(client_addr);
	if ((client_sock = accept(server_sock, (struct sockaddr*)&client_addr, &addrlen)) > 0) {
		for (int i = 0; i < 1024; ++i) {
			if (!sock_list[i]) {
				sock_list[i] = client_sock;
				break;
			}
		}

		// 客户端连接成功，向客户端反馈欢迎信息
		bzero(recv_buf, sizeof(recv_buf));
		inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
		sprintf(recv_buf, "hi, %s welcome to test server service..\n", cip);
		send(client_sock, recv_buf, strlen(recv_buf), 0);
		printf("server info, client connect success , ip %s, port %d\n", cip, ntohs(client_addr.sin_port));
	}
	else if (client_sock == -1){
		// 判断非阻塞
		if (errno == EAGAIN) {
		}
		else {
			perror("accept fail");
			exit(0);
		}
	}

	// 读取客户端请求
	int recv_len;
	for (int i = 0; i < 1024; ++i) {
		if (sock_list[i] == 0) continue;
	bzero(recv_buf, sizeof(recv_buf));
	while ((recv_len = recv(sock_list[i], recv_buf, sizeof(recv_buf), MSG_DONTWAIT)) > 0) {
		flag = 0;
		// 处理客户端请求
		while (recv_len > flag) {
			recv_buf[flag] = toupper(recv_buf[flag]);
			++flag;
		}
		// 反馈结果
		send(sock_list[i], recv_buf, strlen(recv_buf), 0);
		bzero(recv_buf, sizeof(recv_buf));
	// 返回进行下一轮连接等待
	}
	if (recv_len == -1) {
		if (errno == EAGAIN) continue;
	}
	else if (recv_len == 0) {
		// 客户端推出 close
		close(sock_list[i]);
		sock_list[i] = 0;
	}
	}
	}
	return 0;
}
```

---

# 实践——多进程实现

## 说明

主进程一直进行阻塞连接，等待客户端连接，每连接一个客户端则多开一个进程用于与该客户端服务

若某个进程对应的客户端退出了，则该进程也退出，成为僵尸进程

主进程多开了一个线程用于回收这些僵尸进程

为了提高资源利用率，该线程长时间处于睡眠状态，并设置了`SIGCHLD`信号的捕捉行为进行回收僵尸进程，这样只要有进程变成僵尸就会发信号给主进程，然后通过该回收线程进行回收

为了不让主线程处理了该信号，对主线程设置屏蔽字，忽略该信号

## 实现

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>
#include <pthread.h>
#include <signal.h>
#include <sys/wait.h>

#define IP "192.168.19.130"

int server_shutdown;

void sig_sigchld(int signo) {
	pid_t zpid;
	while ((zpid = waitpid(-1, NULL, WNOHANG)) > 0) {
		printf("wait thread 0x%x wait success, zombie %d\n", (unsigned int)pthread_self(), zpid);
	}
}

void* thread_wait(void* x) {
	// 设定捕捉行为
	struct sigaction act, oact;
	act.sa_handler = sig_sigchld;
	act.sa_flags = 0;
	sigemptyset(&act.sa_mask);
	sigaction(SIGCHLD, &act, &oact);

	// 解除屏蔽字
	sigprocmask(SIG_SETMASK, &act.sa_mask, NULL);

	// 等待处理信号
	printf("wait_thread 0x%x, waiting...\n", (unsigned int)pthread_self());
	while (1) sleep(1);
}

int main() {
	struct sockaddr_in server_addr, client_addr;
	int server_sock, client_sock;
	char recv_buf[1500];
	char cip[16];
	int rect_len;
	int flag;
	socklen_t addrlen;
	server_shutdown = 1;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}

	// 绑定网络信息
	if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
		perror("bind fail");
		exit(0);
	}

	// 网络连接监听
	listen(server_sock, 128);

	// 设置屏蔽字
	sigset_t set, oset;
	sigemptyset(&set);
	sigaddset(&set, SIGCHLD);
	sigprocmask(SIG_SETMASK, &set, &oset);
	// 创建线程
	pthread_t tid;
	if (pthread_create(&tid, NULL, thread_wait, NULL) > 0) {
		perror("pthread create fail");
		exit(0);
	}
	
	while (server_shutdown) {
	// 等待建立连接
	addrlen = sizeof(client_addr);
	if ((client_sock = accept(server_sock, (struct sockaddr*)&client_addr, &addrlen)) > 0) {
		// 客户端连接成功，向客户端反馈欢迎信息
		pid_t pid;
		pid = fork();
		if (pid > 0) {
			
		} 
		else if (pid == 0) {
			// 子进程执行
			char recv_buf[1024] = "";
			bzero(recv_buf, sizeof(recv_buf));
			inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
			sprintf(recv_buf, "hi, %s welcome to test server service..\n", cip);
			send(client_sock, recv_buf, strlen(recv_buf), 0);
			printf("server info, client connect success , ip %s, port %d\n", cip, ntohs(client_addr.sin_port));

			// 读取客户端请求
			int recv_len;
			bzero(recv_buf, sizeof(recv_buf));
			while ((recv_len = recv(client_sock, recv_buf, sizeof(recv_buf), 0)) > 0) {
				flag = 0;
				// 处理客户端请求
				while (recv_len > flag) {
					recv_buf[flag] = toupper(recv_buf[flag]);
					++flag;
				}
				// 反馈结果
				send(client_sock, recv_buf, strlen(recv_buf), 0);
				bzero(recv_buf, sizeof(recv_buf));
			}
			// 如果接受长度为0则表示，对方推出，需要结束进程
			if (recv_len == 0) {
				printf("client exit, close sock, child process %d exiting...\n", getpid());
				close(client_sock);
				exit(0);
			}
		}
		else {
			perror("fork fail");
			exit(0);
		}
	}
	else {
		perror("accept fail");
		exit(0);
	}

	}
	return 0;
}
```

---

# 实践——多线程实现

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>
#include <pthread.h>
#include <signal.h>
#include <sys/wait.h>

#define IP "192.168.19.130"

int server_shutdown;

void* yyds(void* p) {
	// 分离
	pthread_detach(pthread_self());
	char recv_buf[1024] = "";
	int recv_len;
	bzero(recv_buf, sizeof(recv_buf));
	int client_sock = *(int*)p;
	int flag;
	while ((recv_len = recv(client_sock, recv_buf, sizeof(recv_buf), 0)) > 0) {
		flag = 0;
		// 处理客户端请求
		while (recv_len > flag) {
			recv_buf[flag] = toupper(recv_buf[flag]);
			++flag;
		}
		// 反馈结果
		send(client_sock, recv_buf, strlen(recv_buf), 0);
		bzero(recv_buf, sizeof(recv_buf));
	}
	// 如果接受长度为0则表示，对方推出，需要结束进程
	if (recv_len == 0) {
		printf("client exit, close sock, thread 0x%x exiting...\n", (unsigned int)pthread_self());
		close(client_sock);
		pthread_exit(0);
	}
}


int main() {
	struct sockaddr_in server_addr, client_addr;
	int server_sock, client_sock;
	char recv_buf[1500];
	char cip[16];
	int rect_len;
	int flag;
	socklen_t addrlen;
	server_shutdown = 1;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}

	// 绑定网络信息
	if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
		perror("bind fail");
		exit(0);
	}

	// 网络连接监听
	listen(server_sock, 128);

	
	while (server_shutdown) {
		// 等待建立连接
		addrlen = sizeof(client_addr);
		if ((client_sock = accept(server_sock, (struct sockaddr*)&client_addr, &addrlen)) > 0) {
			// 连接成功，向客户端发送欢迎
			inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
			sprintf(recv_buf, "hi, %s welcome to test server service..\n", cip);
			send(client_sock, recv_buf, strlen(recv_buf), 0);
			printf("server info, client connect success , ip %s, port %d\n", cip, ntohs(client_addr.sin_port));
			
			// 创建线程来接收信息
			pthread_t pid;
			if ((pthread_create(&pid, NULL, yyds, (void*)&client_sock)) > 0) {
				perror("thread create fail");
				exit(0);
			}
		}
		else {
			perror("accept fail");
			exit(0);
		}
	}
	return 0;
}
```

---

# 多路IO转接技术

多路IO转接技术，主要用于sock事件监听，同时监听若干路socket

一般socket能监听三种事件（实际上不止三种）：

1. 读事件：其他端向socket发送数据，读事件触发
2. 写事件：socket向其他端发送数据，写事件触发
3. 异常事件：socket使用异常，导致异常事件触发

像之前调用的`accept`和`recv`都是通过监听socket的读事件实现的

在采用IO转接方式后，可以降低开销

我们先介绍以下几种，下面三种技术都是同步的：

- `select`
- `poll`
- `epoll`

## select

select最多只能监听1021个socket，不能满足大量监听需求

### 监听集合

```c
fd_set set;
```

监听集合中的每一位对应一个socket，位码0表示取消监听，位码1表示开始监听

### 初始化

```c
FD_ZERO(fd_set* set);
```

将所有为都设置成0

### 置1

```c
FD_SET(int sockfd, &set);
```

将某个sock位置1

### 置0

```c
FD_CLR(int sockfd, &set);
```

将某个位置0

### 判断

```c
int code = FD_ISSET(int sockfd, &set);
```

判断某个位是0还是1，若是1返回1，是0则返回0

### select函数

```c
int ready = select(maxfd + 1, fd_set* rdset, fd_set* wrset, fd_set* errset, struct timeval* val);
```

第一个参数传入监听到哪一位，刚开始的0,1,2都是被系统占用了的：

- 0：stdin
- 1：stdout
- 2：errno

所以至少也是从第3位开始，然而要监听到第三位就得填4，所以是`maxfd + 1`

中间三个参数分别对应读、写、异常监听，会对传入的监听集合进行监听

最后一个参数是用来设置阻塞非阻塞的

#### 阻塞&非阻塞

需要传入`timeval`类型的指针

```c
timeval val;
```

当传入`NULL`时，为阻塞监听

`timeval`有两个属性：

1. seconds：设置秒
2. us：设置微秒

若`val.seconds = 0 && val.us == 0`则是非阻塞

若`val.seconds == 正数 && val.us == 0`

则为阻塞指定秒数等待监听，时间到了没有就绪就直接返回

```c
val.seconds = 5 // 监听5s
```

### 实践

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>

#define IP "192.168.19.130"

int server_shutdown;

int main() {
    struct sockaddr_in server_addr, client_addr;
    int server_sock, client_sock;
    char recv_buf[1500];
    char cip[16];
    int rect_len;
    int flag;
    socklen_t addrlen;
    server_shutdown = 1;

    // 定义网络信息结构体
    bzero(&server_addr, sizeof(server_addr));
    server_addr.sin_family = AF_INET;
    server_addr.sin_port = htons(8080);
    inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
    // server_addr.sin_addr.s_addr = hton(INADDR_ANY);

    // 创建socket
    if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
        perror("sock fail");
        exit(0);
    }

    // 绑定网络信息
    if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
        perror("bind fail");
        exit(0);
    }

    // 网络连接监听
    listen(server_sock, 128);

    // 准备监听集合
    fd_set set, oset; // 传入传出分离
    int ready; // 接收就绪数
    int maxfd = server_sock;
    int client_sock_array[1020]; // client_sock数组
    for (int i = 0; i < 1020; ++i) client_sock_array[i] = -1;

    FD_ZERO(&set);
    FD_SET(server_sock, &set); // 设置第一个监听

    while (server_shutdown) {
        oset = set;

        ready = select(maxfd + 1, &oset, NULL, NULL, NULL);
        while (ready) {
            // 辨别就绪
            if (FD_ISSET(server_sock, &oset)) {
                printf("select server_sock ready call accept...\n");
                addrlen = sizeof(client_addr);
                client_sock = accept(server_sock , (struct sockaddr*)&client_addr, &addrlen);
                FD_SET(client_sock, &set); // 设置监听
                for (int i = 0; i < 1020; ++i)
                    if (client_sock_array[i] == -1) {
                        client_sock_array[i] = client_sock;
                        break;
                    }
                if (maxfd < client_sock) maxfd = client_sock;
                bzero(recv_buf, sizeof(recv_buf));
                bzero(cip, sizeof(cip));
                inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
                sprintf(recv_buf, "hi, %s welcom...\n", cip);
                send(client_sock, recv_buf, strlen(recv_buf), 0);
            }
            else {
                for (int i = 0; i < 1020; ++i) {
                    if (client_sock_array[i] != -1)
                        if (FD_ISSET(client_sock_array[i], &oset)) {
                            printf("select client_sock ready, recv msg...\n");
                            bzero(recv_buf, sizeof(recv_buf));
                            int recv_len;
                            if ((recv_len = recv(client_sock_array[i], recv_buf, sizeof(recv_buf), 0)) > 0) {
                                flag = 0;
                                while (recv_len > flag) {
                                    recv_buf[flag] = toupper(recv_buf[flag]);
                                    ++flag;
                                }
                                send(client_sock_array[i], recv_buf, strlen(recv_buf), 0);
                                break;
                            }
                            else if(recv_len == 0) {
                                printf("select client sock ready, client exit...\n");
                                FD_CLR(client_sock_array[i], &set); // 取消监听
                                close(client_sock_array[i]);
                                client_sock_array[i] = -1;
                                break;
                            }
                        }
                }
            }


            --ready;
        }

    }
    close(server_sock);
    return 0;
}
```

### 优点&缺点

优点：

1. 可以通过多路监听的方式让服务器模型实现单进程的一对多效果，开销小，实现简单
2. select跨平台语言兼容性
3. select支持微秒级别定时阻塞，可以满足一些定时时间精度较高的需求

缺点：

1. select最大监听1021个socket，不能满足大量监听的需求
2. 轮询问题，监听是采用轮询查看是否就绪，这导致如果轮询开销较大（占用CPU），会导致IO处理性能呈线性下降，所以为了避免这种情况，将轮询开销限制在可以接受的范围（1024）
3. 随着select持续多轮监听，会出现大量重复的拷贝开销和挂载开销，这些开销是没有任何意义的
4. select设置监听事件是以监听集合为单位批量处理的，无法对不同的sock监听不同的事件，不够灵活，而且监听的事件种类较少

### 使用问题

- select没有实现传入传出分离设置，需要用户自行分离
- select监听到就绪后，只返回就绪数量，不返回就绪的socket，需要用户自行遍历查找
- 单进程模型问题：代码串行执行所以不允许某个环节出现阻塞，其次业务复杂度要低，因为最大1020/s处理完任务

## poll

poll不适用`fd_set`作为监听集合，它使用自定义长度的结构体数组作为监听集合，数组类型是`struct pollfd`

### `pollfd`结构体

```c
struct pollfd var;
```

#### 设置监听socket

```c
var.fd = sockfd;
```

#### 设置监听事件

设置监听事件，分别为读，写，异常，还有例如`POLLHUP`，`POLLPRI`，`POLLRDHUP`等其他事件可以监听

```c
var.events = POLLIN | POLLOUT | POLLERR
```

#### 判断就绪

当监听的socket就绪后传出就绪事件，用于判断就绪

```c
var.revents = POLLIN
```

### poll函数

```c
int ready = poll(listen_array, 最大监听数量, int timeout)
```

返回的ready依旧是就绪数

最后一个参数是用来设置是否阻塞的：

- timeout = -1：阻塞

- timeout = 0：非阻塞

- timeout > 0：定时阻塞监听，默认以毫秒级别定时，如果系统不支持则为秒

	> 比如传入的是5，若系统支持毫秒这是5毫秒，若不支持，则是5秒

### 优点&缺点

优点：

1. poll进行了事件的传入传出分离，events用于传入监听事件，revents用于传出就绪事件，便于用户判断就绪
2. 可监听的socket事件更丰富，而且设置监听更灵活

缺点：

1. poll的兼容性比较差，只有某些linux支持，poll只支持毫秒级别定时阻塞
2. 可以自定义长度监听数组，但是也不宜过大，因为收到轮询问题限制
3. poll依旧存在轮询问题
4. 多轮使用，依然存在重复的拷贝开销和挂载开销问题

### 使用问题

- 只返回就绪数量不返回就绪的socket，需要用户自行遍历查找
- 单进程模型问题，代码串行执行所以不允许某个环节出现阻塞，其次业务复杂度要低，也是轮询的问题

### 实践

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>
#include <poll.h>

#define IP "192.168.19.130"
#define NUM 4096

int server_shutdown;

int main() {
	struct sockaddr_in server_addr, client_addr;
	int server_sock, client_sock;
	char recv_buf[1500];
	char cip[16];
	int rect_len;
	int flag;
	socklen_t addrlen;
	server_shutdown = 1;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}

	// 绑定网络信息
	if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
		perror("bind fail");
		exit(0);
	}

	// 网络连接监听
	listen(server_sock, 128);
	
	// 准备监听集合
	int ready; // 接收就绪数
	struct pollfd client_sock_array[NUM]; // client_sock数组
	for (int i = 0; i < NUM; ++i) {
		client_sock_array[i].fd = -1;
		client_sock_array[i].events = POLLIN;
	}

	client_sock_array[0].fd = server_sock; // 设置第一个监听

	while (server_shutdown) {
		ready = poll(client_sock_array, NUM, -1);
		while (ready) {
			// 辨别就绪
			if (client_sock_array[0].revents == POLLIN) {
				printf("select server_sock ready call accept...\n");
				addrlen = sizeof(client_addr);
				client_sock = accept(server_sock , (struct sockaddr*)&client_addr, &addrlen);
				for (int i = 0; i < NUM; ++i)
					if (client_sock_array[i].fd == -1) {
						client_sock_array[i].fd = client_sock;
						break;
					}
				bzero(recv_buf, sizeof(recv_buf));
				bzero(cip, sizeof(cip));
				inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
				sprintf(recv_buf, "hi, %s welcom...\n", cip);
				send(client_sock, recv_buf, strlen(recv_buf), 0);
				client_sock_array[0].revents = 0;
			}
			else {
				for (int i = 1; i < NUM; ++i) {
					if (client_sock_array[i].fd != -1)
						if (client_sock_array[i].revents == POLLIN) {
							printf("select client_sock ready, recv msg...\n");
							bzero(recv_buf, sizeof(recv_buf));
							int recv_len;
							client_sock_array[i].revents = 0;
							if ((recv_len = recv(client_sock_array[i].fd, recv_buf, sizeof(recv_buf), 0)) > 0) {
								flag = 0;
								while (recv_len > flag) {
									recv_buf[flag] = toupper(recv_buf[flag]);
									++flag;
								}
								send(client_sock_array[i].fd, recv_buf, strlen(recv_buf), 0);
								break;
							}
							else if(recv_len == 0) {
								printf("select client sock ready, client exit...\n");
								client_sock_array[i].fd = -1; // 取消监听
								close(client_sock_array[i].fd);
								break;
							}
						}
				}
			}


			--ready;
		}

	}
	close(server_sock);
	return 0;
}
```

### 注意点

在默认情况下，像上述代码，数组开到4096是会出错的

我们使用命令查看一下最大文件打开数：

```bash
ulimit -a
```

其中的`open file`项对应的数字就是最大能打开打的文件数目，我们发现最大只能打开1024个，这也就是为什么数组开到4096会出错了，因为根本不能打开那么多的文件

我们要做的是修改最大打开文件数

#### 临时修改

调用指令：

```bash
ulimit -n 值
```

可以暂时修改最大打开文件数量，只对当前终端有效

#### 永久修改

首先我们要查找系统的文件数：

```bash
cat /proc/sys/fs/file-max
```

发现我们的系统有20w左右的文件数

于是下一步去修改一下相关配置文件：

```bash
sudo vi /etc/security/limits.conf
```

在最后添加两行即可

```bash
#<domain>      <type>  <item>         <value>
#

#*               soft    core            0
#root            hard    core            100000
#*               hard    rss             10000
#@student        hard    nproc           20
#@faculty        soft    nproc           20
#@faculty        hard    nproc           50
#ftp             hard    nproc           0
#ftp             -       chroot          /ftp
#@student        -       maxlogins       4
# 下面两行为自己添加的
*               soft    nofile          60000
*               hard    nofile          200000
```

然后再重启一下计算机即可

## epoll

epoll使用红黑树作为监听集合，每个节点都是一个结构体

### 节点结构体

```c
struct epoll_event node;
```

设置需要监听的sock：

```c
node.data.fd = sockfd;
```

设置监听的事件（当然除了以下举例的这些事件还有很多实践）：

```c
node.events = EPOLLIN | EPOLLOUT | EPOLLERR
```

该结构体还内置了一个回调函数，但并不需要我们来设置

### 就绪数组

epoll函数需要传入就绪数组作为输出参数，最终就绪的节点会被放入数组传出，供用户处理

```c
struct epoll_event ready_array[LISTEN_MAX];
```

### 创建树

```c
int epfd = epoll_create(LISTEN_MAX);
```

参数为红黑树的大小，成功则返回树的描述符，后续用epfd来访问修改树

### 修改树

```c
epoll_ctl(epfd, int cmd, int sockfd, struct epoll_event* node);
```

第一个参数传入树的描述符

第二个参数传入处理的模式：

- `EPOLL_CTL_ADD`：添加节点

- `EPOLL_CTL_DEL`：删除节点

- `EPOLL_CTL_MOD`：修改节点

	**注意：修改不允许修改监听的socket，只能修改监听的事件**

第三个参数传入监听的socket，树上就以该值作为id

第四个参数传入节点

### epoll_wait函数

```c
int ready = epoll_wait(epfd, ready_array, LISTEN_MAX, -1);
```

第一个参数先传入树的描述符

第二个参数传入就绪队列

第三个参数传入监听的最大数目

第四个参数就是`timeout`，跟poll里的那个一样传。用来设置阻塞的

返回值也是就绪个数

### 实践

```c
#include <stdio.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <netdb.h>
#include <unistd.h>
#include <ctype.h>
#include <sys/epoll.h>

#define IP "192.168.19.130"
#define NUM 1025

int server_shutdown;

int main() {
	struct sockaddr_in server_addr, client_addr;
	int server_sock, client_sock;
	char recv_buf[1500];
	char cip[16];
	int rect_len;
	int flag;
	socklen_t addrlen;
	server_shutdown = 1;

	// 定义网络信息结构体
	bzero(&server_addr, sizeof(server_addr));
	server_addr.sin_family = AF_INET;
	server_addr.sin_port = htons(8080);
	inet_pton(AF_INET, IP, &server_addr.sin_addr.s_addr);
	// server_addr.sin_addr.s_addr = hton(INADDR_ANY);

	// 创建socket
	if ((server_sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
		perror("sock fail");
		exit(0);
	}

	// 绑定网络信息
	if (bind(server_sock, (struct sockaddr*)&server_addr, sizeof(server_addr)) == -1) {
		perror("bind fail");
		exit(0);
	}

	// 网络连接监听
	listen(server_sock, 128);
	
	// 准备监听树
	int epfd;
	epfd = epoll_create(NUM);
	struct epoll_event ready_array[NUM];
	struct epoll_event node;
	node.data.fd = server_sock;
	node.events = EPOLLIN;
	epoll_ctl(epfd, EPOLL_CTL_ADD, server_sock, &node); // 添加监听节点
	int i;
	int ready; // 接收就绪数


	while (server_shutdown) {
		ready = epoll_wait(epfd, ready_array, NUM, -1);
		while (ready) {
			i = 0;
			// 辨别就绪
			if (ready_array[i].data.fd == server_sock) {
				printf("epoll server_sock ready call accept...\n");
				addrlen = sizeof(client_addr);
				client_sock = accept(server_sock , (struct sockaddr*)&client_addr, &addrlen);

				node.data.fd = client_sock;
				node.events = EPOLLIN;
				epoll_ctl(epfd, EPOLL_CTL_ADD, client_sock, &node); // 添加监听

				bzero(recv_buf, sizeof(recv_buf));
				bzero(cip, sizeof(cip));
				inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, 16);
				sprintf(recv_buf, "hi, %s welcom...\n", cip);
				send(client_sock, recv_buf, strlen(recv_buf), 0);
			}
			else {
							printf("epoll client_sock ready, recv msg...\n");
							bzero(recv_buf, sizeof(recv_buf));
							int recv_len;
							if ((recv_len = recv(ready_array[i].data.fd, recv_buf, sizeof(recv_buf), 0)) > 0) {
								flag = 0;
								while (recv_len > flag) {
									recv_buf[flag] = toupper(recv_buf[flag]);
									++flag;
								}
								send(ready_array[i].data.fd, recv_buf, strlen(recv_buf), 0);
							}
							else if(recv_len == 0) {
								printf("select client sock ready, client exit...\n");
								close(ready_array[i].data.fd);
								epoll_ctl(epfd, EPOLL_CTL_DEL, ready_array[i].data.fd, NULL);
							}
						}
			--ready;
			++i;
		}

	}
	close(server_sock);
	return 0;
}
```

---

### 监听模式

epoll的监听模式分为水平触发和边缘触发：

#### 水平触发（负责）

在水平触发模式下，产生就绪后向上层发送一次处理通知，后续持续检测数据处理情况，如果数据没有及时处理完毕，则没隔一段时间向上层发送处理通知

在水平模式下，执行epoll_wait不会阻塞监听，而是立即返回，返回值为未处理的就绪数量

#### 边缘触发（不负责）

在边缘模式下，就绪返回后会向上层发送一次处理通知，但只有一次，后续用户是否处理就绪都与epoll无关

开销虽然比较小，但是会导致数据丢失，连接丢失，用户需要自行保证数据读取完整

因此我们使用边缘出发读数据的时候就要采用非阻塞循环读

#### 设置

设置触发模式很简单，可以对不同的sock设置不同的监听模式

```c
node.data.fd = sock;
node.events = EPOLLIN | EPOLLET // 设置边缘触发
```

如果要设置水平触发的话就用`EPOLLLT`，默认为水平触发

#### epollshot避免多线程访问sock冲突

epollshot会在sock就绪后将该sock从监听树中删除

在该线程处理完毕后再将该sock添加回监听树

设置的时候只需要在监听节点的事件上多或上一个`EPOLLONESHOT`就行

```c
struct epoll_event node;
node.data.fd = sock;
node.events = EPOLLIN | EPOLLONESHOT;
epoll_ctl(epfd, EPOLL_CTL_ADD, sock, &node);S
```

**注意：这里在完成任务后需要手动将sock添加回监听树**

**这里使用的是`EPOLL_CTL_MOD`哦**

```c
struct epoll_event node;
node.data.fd = sock;
node.events = EPOLLIN | EPOLLONESHOT;
epoll_ctl(epfd, EPOLL_CTL_MOD, sock, &node);
```

# 实践——epoll+线程池模型

**注意：本项目的监听事件全用`epolloneshot`优化了**

通过epoll完成大量sock的网络事件监听，提高服务端对socket的监听能力，线程池能进行并发处理，提高处理性能

## 头文件

头文件定义为：

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <ctype.h>
#include <sys/socket.h>
#include <arpa/inet.h>
#include <pthread.h>
#include <sys/epoll.h>
#include <errno.h>

#define SERVER_IP "192.168.19.131"
#define SERVER_PORT 8080
#define RECV_BUF 1500
#define EPOLL_MAX 100000
#define IP 16
#define TRUE 1
#define BACKLOG 128

int epfd; // 全局监听树描述符

typedef struct {
	void* (*business)(int);
	void* arg;
	int sock;
} bs_t;

typedef struct {
	int thread_max; // 线程数量最大值
	int thread_min; // 线程数量最小值
	int thread_alive; // 存活线程个数
	int thread_busy; // 繁忙
	int thread_shutdown; // 开关
	int thread_exitcode; // 缩减码
	bs_t* list; // 任务队列
	int front; // 头索引
	int rear; // 尾索引
	int cur;  // 有效任务数
	int max; // 队列最大大小
	pthread_mutex_t lock; // 互斥锁
	pthread_cond_t Not_Empty; // 消费者条件变量
	pthread_cond_t Not_Full; // 生产者条件变量
	pthread_t* ctids; // 消费者tid
	pthread_t mtid; // 管理者tid
} pl_t;

int pl_netinit(void); // 网络初始化
int pl_epoll_create(int sockfd); // epoll创建初始化
int pl_epoll_listen(pl_t*, int sockfd); // 持续监听sock网络事件
pl_t* pl_create(int Max, int Min, int Qmax); // 线程池创建初始化
int pl_destroy(pl_t*); // 摧毁线程池资源
int producer_add_business(pl_t* pl, bs_t bs); // 执行一次添加一次任务，生产者任务
void* manager(void* arg); // 管理者任务
void* customer(void*); // 消费者任务
void* Accept_business(int); // 连接业务
void* Response_business(int); // 处理
int if_thread_alive(pthread_t tid); // 查看线程是否存活
```

## 主函数

主函数里的函数调用为：

```c
#include <server.h>

int main() {
	int sock;
	pl_t* pl = NULL;
	sock = pl_netinit();
	printf("hello\n");
	pl_epoll_create(sock);
	pl = pl_create(100, 10, 1000);
	pl_epoll_listen(pl, sock);
	return 0;
}
```

## 线程池

线程池是个线性容器，便于控制，管理，使用线程

线程池有以下优点：

1. 提高线程的重用性，线程可以为若干个不同的客户端处理业务
2. 预创建，线程池内部总是保留一部分闲置可用的线程，当任务到来，可以立即处理
3. 线程动态管理，扩容与缩减
4. 动态灵活的任务设计，提高线程池的可用性
5. 生产者消费者完成线程池中的任务传递（互斥锁+条件变量）

一般线程池的线程指导意见为CPU核数的两倍

## 扩容与缩减

扩容条件为：

- 业务量 >= 可用线程数量，扩容线程
- 繁忙线程占存活线程的70%，扩容线程
- 当前线程数量 + 扩容数量 <= 最大数量

缩减条件为：

- 闲线程是繁忙线程的倍数，缩减一部分线程
- 当前线程数量 - 缩减数量 >= 最小数量

## 线程池结构体

以下是自己定义的结构体：

```c
typedef struct {
	int thread_max; // 线程数量最大值
	int thread_min; // 线程数量最小值
	int thread_alive; // 存活线程个数
	int thread_busy; // 繁忙
	int thread_shutdown; // 开关
	int thread_exitcode; // 缩减码
	bs_t* list; // 任务队列
	int front; // 头索引
	int read; // 尾索引
	int cur;  // 有效任务数
	int max; // 队列最大大小
	pthread_mutex_t lock; // 互斥锁
	pthread_cond_t Not_Empty; // 消费者条件变量
	pthread_cond_t Not_Full; // 生产者条件变量
	pthreadd_t* ctids; // 消费者tid
	pthread_t mtid; // 管理者tid
} pl_t;
```

## epoll监听树创建

在初始化好网络后，就可以将服务器的sock挂到监听树上了

```c
#include "server.h"

int pl_epoll_create(int sockfd) {
	if ((epfd = epoll_create(EPOLL_MAX)) == -1) {
		perror("epoll create failed");
		exit(0);
	}
	printf("epoll create success\n");

	struct epoll_event node;
	node.data.fd = sockfd;
	node.events = EPOLLIN | EPOLLONESHOT;
	if (epoll_ctl(epfd, EPOLL_CTL_ADD, sockfd, &node)) {
		perror("epoll_ctl fail");
		exit(0);
	}
	printf("server node add success\n");
	return 0;
}
```

## 线程池初始化

在成功创建线程数后，我们可以进行线程池的初始化（**其实这俩谁先初始化都行**），创建一些原始的线程来等待接收任务

```c
#include "server.h"

pl_t* pl_create(int Max, int Min, int Qmax) {
	pl_t* pl = NULL;
	if ((pl = (pl_t*)malloc(sizeof(pl_t))) == NULL) {
		perror("malloc pl failed");
		exit(0);
	}
	printf("malloc pl success\n");
	
	pl->thread_max = Max;
	pl->thread_min = Min;
	pl->thread_alive = 0;
	pl->thread_busy = 0;
	pl->thread_shutdown = 1;
	pl->thread_exitcode = 0;

	if ((pl->list = (bs_t*)malloc(sizeof(bs_t) * Qmax)) == NULL) {
		perror("malloc list failed");
		exit(0);
	}
	if ((pl->ctids = (pthread_t*)malloc(sizeof(pthread_t) * Max)) == NULL) {
		perror("malloc ctids failed");
		exit(0);
	}
	printf("malloc list and ctids success\n");
	
	// 初始化ctids，初始化为0
	bzero(pl->ctids, sizeof(pthread_t) * Max);
	pl->front = 0;
	pl->rear = 0;
	pl->cur = 0;
	pl->max = Qmax;

	if (pthread_mutex_init(&pl->lock, NULL) != 0 || pthread_cond_init(&pl->Not_Empty, NULL) != 0 || pthread_cond_init(&pl->Not_Full, NULL) != 0) {
		perror("init lock or cond failed");
		exit(0);
}
	printf("mutex and cond init success\n");
	
	// 创建首批线程
	int err;
	if ((err = pthread_create(&pl->mtid, NULL, manager, (void*)pl)) > 0) {
		printf("pl_create failed, create manager thread error: %s\n", strerror(err));
		exit(0);
	}
	for (int i = 0; i < pl->thread_min; ++i) {
		if ((err = pthread_create(&pl->ctids[i], NULL, customer, (void*)pl)) > 0) {
			printf("pl_create failed, create error:%s\n", strerror(err));
			exit(0);
		}
		pthread_mutex_lock(&pl->lock);
		++(pl->thread_alive);
		pthread_mutex_unlock(&pl->lock);
	}
	return pl;
}
```

## manager线程

消费者线程的扩容和缩减都是通过manager线程多次检测实现的，它会根据忙碌线程占全部存活线程的占比来调整线程数量

```c
#include <server.h>

void* manager(void* arg) {
	pl_t* pl = (pl_t*)arg;
	int alive, busy, cur;
	int add;
	int i;
	int err;
	int timeout = 1;
	pthread_detach(pthread_self());
	while (pl->thread_shutdown) {
		pthread_mutex_lock(&pl->lock);
		alive = pl->thread_alive;
		busy = pl->thread_busy;
		cur = pl->cur;
		pthread_mutex_unlock(&pl->lock);

		if ((cur >= alive - busy || (double)busy / alive * 100 >= 40) && alive + pl->thread_min <= pl->thread_max) {
			for (i = 0, add = 0; i < pl->thread_max && add < pl->thread_min; ++i) {
				if (pl->ctids[i] == 0 || !if_thread_alive(pl->ctids[i])) {
					if ((err = pthread_create(&pl->ctids[i], NULL, customer, pl)) > 0) {
						printf("manager create thread failed:%s\n", strerror(err));
						exit(0);
					}
					++add;
					pthread_mutex_lock(&pl->lock);
					++pl->thread_alive;
					pthread_mutex_unlock(&pl->lock);
				}
			}
		}

		if (busy * 2 < alive - busy && alive - pl->thread_min >= pl->thread_min) {
			pthread_mutex_lock(&pl->lock);
			pl->thread_exitcode = pl->thread_min; // 缩减量
			pthread_mutex_unlock(&pl->lock);
			for (int i = 0; i < pl->thread_min; ++i)
				pthread_cond_signal(&pl->Not_Empty), --pl->thread_alive;
		}
		printf("alive %d, busy %d, cur %d\n", pl->thread_alive, pl->thread_busy, pl->cur);
		sleep(timeout);
	}
	printf("manager 0x%x, exiting...\n", (unsigned int)pthread_self());
	pthread_exit(NULL);
}
			
```

### 判断线程是否存活

线程死亡后仍然会占用`ctid`数组的位置，所以我们在创建新线程的时候要去判断，如果该位的tid为0那么肯定是没被使用的，如果不是则也不一定是被占用的，也有可能是之前的线程死亡，而且并没有修改改数组值

我们通过`pthread_kill()`函数判断

```c
#include <server.h>

int if_thread_alive(pthread_t tid) {
	if (pthread_kill(tid, 0) == 0)
		return 1;
	else 
		return 0;
}
```

## 消费者线程

主线程是生产者线程，负责管理消费者数量的是管理者线程，其余的用于工作的全为消费者线程，他们在存活期间反复判断任务池是否是有任务，如果有则接过任务，并调用任务中的函数完成任务，函数返回后又恢复到空闲状态，继续反复查看任务池是否有新任务

```c
#include "server.h"

void* customer(void* arg) {
	bs_t tmp;
	pl_t* pl = (pl_t*)arg;
	pthread_detach(pthread_self());
	while (pl->thread_shutdown) {
		pthread_mutex_lock(&pl->lock);
		while (pl->cur == 0) {
			pthread_cond_wait(&pl->Not_Empty, &pl->lock);
			if (pl->thread_shutdown != 1) {
				--pl->thread_alive;
				pthread_mutex_unlock(&pl->lock);
				pthread_exit(NULL);
			}
		}
		tmp.business = pl->list[pl->rear].business;
		tmp.sock = pl->list[pl->rear].sock;
		--pl->cur;
		pl->rear = (pl->rear + 1) % pl->max;
		++(pl->thread_busy);
		pthread_mutex_unlock(&pl->lock);
		pthread_cond_signal(&pl->Not_Full);
		// 执行任务
		(*tmp.business)(tmp.sock);
		pthread_mutex_lock(&pl->lock);
		--(pl->thread_busy);
		pthread_mutex_unlock(&pl->lock);
	}
	printf("customer -x%x exiting, thread_sutdown closed\n", (unsigned int)pthread_self());
	pthread_exit(NULL);
}
```

## 生产者线程

生产者线程也就是主线程，在完成所有初始化任务后，进入循环重复监听是否有客户端来连接或者已连接的客户端是否有要处理的任务。

如果有，则将这些作为任务放入任务池，供消费者线程来消费完成

如果是服务器sock收到了信息就创建新连接，连接新的客户端；如果不是，那么就是已连接的客户端有任务需要处理

```c
#include "server.h"

int pl_epoll_listen(pl_t* pl, int sockfd) {
	int ready;
	struct epoll_event ready_array[EPOLL_MAX];
	int i;
	bs_t bs;
	while (pl->thread_shutdown) {
		if ((ready = epoll_wait(epfd, ready_array, EPOLL_MAX, -1)) == -1) {
			perror("listen fail");
			exit(0);
		}
		i = 0;
		while (ready) {
			if (ready_array[i].data.fd == sockfd) {
				bs.business = Accept_business;
				bs.arg = NULL;
				bs.sock = sockfd;
				producer_add_business(pl, bs);
				printf("producer add accept work\n");
			}
			else {
				bs.business = Response_business;
				bs.arg = NULL;
				bs.sock = ready_array[i].data.fd;
				producer_add_business(pl, bs);
				printf("producer add response work\n");
			}
			--ready;
			++i;
		}
	}
	return 0;
}
```

### 添加任务

为了空间合理利用，这里使用环形队列模拟任务池

```c
#include "server.h"

int producer_add_business(pl_t* pl, bs_t bs) {
	if (pl->thread_shutdown) {
		pthread_mutex_lock(&pl->lock);

		if (pl->cur == pl->max) 
			pthread_cond_wait(&pl->Not_Full, &pl->lock);

		if (pl->thread_shutdown != 1) {
			pthread_mutex_unlock(&pl->lock);
			printf("master thread, thread_shutdown is 0\n");
		}
		
		pl->list[pl->front].business = bs.business;
		pl->list[pl->front].sock = bs.sock;
		++(pl->cur);
		pl->front = (pl->front + 1) % pl->max; // 环形偏移计算
		pthread_mutex_unlock(&pl->lock);
		pthread_cond_signal(&pl->Not_Empty);
	}
	else {
		printf("thread shutdown closed\n");
	}
	return 0;
}
```

---

## `epolloneshot`优化的响应函数

```c
#include <server.h>

void* Response_business(int sockfd) {
	printf("thread 0x%x get response work\n", (unsigned int)pthread_self());
	int recv_len;
	int flag = 0;
	char buffer[RECV_BUF];
	while (1) {
		recv_len = recv(sockfd, buffer, sizeof(buffer), MSG_DONTWAIT);
		if (recv_len > 0) {	
			while (recv_len > flag) {
				buffer[flag] =toupper(buffer[flag]);
				++flag;
			}
			send(sockfd, buffer, strlen(buffer), MSG_NOSIGNAL);
		}
		else if (recv_len == -1) {
			if (errno == EAGAIN) {
				// 重新挂上节点
				struct epoll_event node;
				node.data.fd = sockfd;
				node.events = EPOLLIN | EPOLLONESHOT;
				epoll_ctl(epfd, EPOLL_CTL_MOD, sockfd, &node);
			}
			else {
				perror("response_business recv failed");
			}
			break;
		}
		else if (recv_len == 0) {
			printf("client sock %d, exit\n", sockfd);
			close(sockfd);
			if ((epoll_ctl(epfd, EPOLL_CTL_DEL, sockfd, NULL)) == -1)
				perror("Response_business, epoll_ctl delete fail");
			break;
		}
	}
	return NULL;
}
```

---

## `epolloneshot`优化的连接函数

```c
#include <server.h>

void* Accept_business(int sockfd) {
	printf("thread 0x%x get accept work\n", pthread_self());
	int client_fd;
	struct sockaddr_in client_addr;
	socklen_t addrlen;
	char buffer[RECV_BUF];
	char cip[IP];
	struct epoll_event node, servernode;
	addrlen = sizeof(client_addr);
	if ((client_fd = accept(sockfd, (struct sockaddr*)&client_addr, &addrlen)) == -1)
		perror("Accept_business, accept failed");
	if (client_fd > 0) {
		bzero(buffer, RECV_BUF);
		bzero(cip, IP);
		inet_ntop(AF_INET, &client_addr.sin_addr.s_addr, cip, IP);
		sprintf(buffer, "hi, [%s] welcome to colin test server version 1.0\n", cip);
		send(client_fd, buffer, strlen(buffer), MSG_NOSIGNAL);
		node.data.fd = client_fd;
		servernode.data.fd = sockfd;
		node.events = EPOLLIN | EPOLLONESHOT;
		servernode.events = EPOLLIN | EPOLLONESHOT;
		if ((epoll_ctl(epfd, EPOLL_CTL_ADD, client_fd, &node)) == -1)
			perror("accept_business, epoll_ctl call failed");
		if ((epoll_ctl(epfd, EPOLL_CTL_MOD, sockfd, &servernode)) == -1)
			perror("accept_business, epoll_ctl call failed");
		return NULL;
	}
	printf("ACCEPT failed\n");
	return NULL;
}
```

